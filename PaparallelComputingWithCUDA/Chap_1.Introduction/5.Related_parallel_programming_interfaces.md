# 5. Các giao diện lập trình song song liên quan

Nhiều ngôn ngữ và mô hình lập trình song song đã được đề xuất trong vài thập kỷ qua ([Mattson et al., 2004](#mattson-tg-sanders-ba-massingill-bl-2004-patterns-for-parallel-programming-addison-wesley)). Những ngôn ngữ và mô hình được sử dụng rộng rãi nhất là OpenMP ([Open, 2005](#openmp-architecture-review-board-2005-openmp-application-program-interface)) cho các hệ thống đa xử lý bộ nhớ chia sẻ và Giao diện Truyền Thông Điệp (Message Passing Interface - MPI) ([MPI, 2009](#message-passing-interface-forum-2009-mpi-a-message-passing-interface-standard-version-22-httpwwwmpi-forumorgdocsmpi-22mpi22-reportpdf-september-4)) cho điện toán cụm có khả năng mở rộng. Cả hai đều đã trở thành các giao diện lập trình chuẩn được hỗ trợ bởi các nhà cung cấp máy tính lớn.

Một triển khai OpenMP bao gồm một trình biên dịch và một hệ thống thời gian chạy. Lập trình viên chỉ định các chỉ thị (lệnh) và pragma (gợi ý) về một vòng lặp cho trình biên dịch OpenMP. Với các chỉ thị và pragma này, trình biên dịch OpenMP tạo ra mã song song. Hệ thống thời gian chạy hỗ trợ việc thực thi mã song song bằng cách quản lý các luồng và tài nguyên song song. OpenMP ban đầu được thiết kế cho việc thực thi trên CPU và đã được mở rộng để hỗ trợ việc thực thi trên GPU. Ưu điểm chính của OpenMP là nó cung cấp tự động hóa trình biên dịch và hỗ trợ thời gian chạy để trừu tượng hóa nhiều chi tiết lập trình song song khỏi lập trình viên. Tự động hóa và trừu tượng hóa như vậy có thể giúp làm cho mã ứng dụng có khả năng di chuyển cao hơn giữa các hệ thống do các nhà cung cấp khác nhau sản xuất cũng như các thế hệ hệ thống khác nhau từ cùng một nhà cung cấp. Chúng tôi gọi thuộc tính này là khả năng di chuyển hiệu năng (performance portability). Tuy nhiên, lập trình hiệu quả trong OpenMP vẫn yêu cầu lập trình viên phải hiểu tất cả các khái niệm lập trình song song chi tiết có liên quan. Bởi vì CUDA cho phép lập trình viên kiểm soát rõ ràng các chi tiết lập trình song song này, nên nó là một phương tiện học tập tuyệt vời ngay cả đối với những người muốn sử dụng OpenMP làm giao diện lập trình chính của họ. Hơn nữa, theo kinh nghiệm của chúng tôi, các trình biên dịch OpenMP vẫn đang phát triển và cải tiến. Nhiều lập trình viên có thể sẽ cần sử dụng các giao diện kiểu CUDA cho các phần mà trình biên dịch OpenMP chưa đáp ứng được.

Mặt khác, MPI là một giao diện lập trình trong đó các nút tính toán trong cụm không chia sẻ bộ nhớ (MPI, 2009). Tất cả việc chia sẻ và tương tác dữ liệu phải được thực hiện thông qua việc truyền thông điệp rõ ràng. MPI đã được sử dụng rộng rãi trong HPC. Các ứng dụng được viết bằng MPI đã chạy thành công trên các hệ thống máy tính cụm với hơn 100.000 nút. Ngày nay, nhiều cụm HPC sử dụng các nút CPU/GPU không đồng nhất. Lượng công sức cần thiết để chuyển đổi một ứng dụng sang MPI có thể khá cao, do thiếu bộ nhớ chia sẻ giữa các nút tính toán. Lập trình viên cần thực hiện phân hoạch miền để phân vùng dữ liệu đầu vào và đầu ra trên các nút riêng lẻ. Trên cơ sở phân hoạch miền, lập trình viên cũng cần gọi các hàm gửi và nhận thông điệp để quản lý việc trao đổi dữ liệu giữa các nút. Ngược lại, CUDA cung cấp bộ nhớ chia sẻ cho việc thực thi song song trong GPU để giải quyết khó khăn này. Mặc dù CUDA là một giao diện hiệu quả với mỗi nút, hầu hết các nhà phát triển ứng dụng cần sử dụng MPI để lập trình ở cấp cụm. Hơn nữa, đã có sự hỗ trợ ngày càng tăng cho lập trình đa GPU trong CUDA thông qua các API như Thư viện Truyền thông Tập thể NVIDIA (NCCL). Do đó, điều quan trọng là một lập trình viên song song 1.5 Giao diện lập trình song song liên quan 13 trong HPC cần hiểu cách thực hiện lập trình MPI/CUDA kết hợp trong các cụm máy tính hiện đại sử dụng các nút đa GPU, một chủ đề được trình bày trong Chương 20, Lập trình cụm máy tính không đồng nhất.

Năm 2009, một số công ty lớn trong ngành, bao gồm Apple, Intel, AMD/ATI, và NVIDIA, đã cùng nhau phát triển một mô hình lập trình chuẩn hóa gọi là Ngôn ngữ Tính toán Mở (OpenCL) ([The Khronos Group, 2009](#the-khronos-group-2009-the-opencl-specification-version-10-httpwwwkhronos-orgregistryclspecsopencl-1029pdf)). Tương tự như CUDA, mô hình lập trình OpenCL định nghĩa các phần mở rộng ngôn ngữ và API thời gian chạy để cho phép lập trình viên quản lý song song và phân phối dữ liệu trong các bộ xử lý song song lớn. So với CUDA, OpenCL dựa nhiều hơn vào API và ít hơn vào các phần mở rộng ngôn ngữ. Điều này cho phép các nhà cung cấp nhanh chóng thích ứng các trình biên dịch và công cụ hiện có của họ để xử lý các chương trình OpenCL. OpenCL là một mô hình lập trình chuẩn hóa ở chỗ các ứng dụng được phát triển trong OpenCL có thể chạy chính xác mà không cần sửa đổi trên tất cả các bộ xử lý hỗ trợ các phần mở rộng ngôn ngữ và API của OpenCL. Tuy nhiên, người ta có thể cần phải sửa đổi các ứng dụng để đạt được hiệu năng cao cho một bộ xử lý mới.

Những người quen thuộc với cả OpenCL và CUDA đều biết rằng có sự tương đồng đáng kể giữa các khái niệm và tính năng chính của OpenCL và CUDA. Điều đó có nghĩa là, một lập trình viên CUDA có thể học lập trình OpenCL với rất ít nỗ lực. Quan trọng hơn, hầu hết mọi kỹ thuật được học khi sử dụng CUDA đều có thể dễ dàng áp dụng cho lập trình OpenCL.

## References

#### Mattson, T.G., Sanders, B.A., Massingill, B.L., 2004. Patterns for Parallel Programming. Addison-Wesley.

#### OpenMP Architecture Review Board, 2005. OpenMP application program interface.

#### Message Passing Interface Forum, 2009. MPI A Message Passing Interface Standard Version 2.2. http://www.mpi-forum.org/docs/mpi-2.2/mpi22-report.pdf, September 4.

#### The Khronos Group, 2009. The OpenCL Specification version 1.0. http://www.khronos. org/registry/cl/specs/opencl-1.0.29.pdf.
